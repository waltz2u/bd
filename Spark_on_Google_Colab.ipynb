{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark on Google Colab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waltz2u/bd/blob/master/Spark_on_Google_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKqjPw2LJ4op",
        "colab_type": "text"
      },
      "source": [
        "# Spark Installation on Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLOe7TqgJ_WO",
        "colab_type": "text"
      },
      "source": [
        "The following download OpenJDK Java, and Spark, unzip Spark to a directory on Google Drive, and install FindSpark, a library that makes it easy for Python to\n",
        "find Spark.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5HTg9ntvFb6",
        "colab_type": "code",
        "outputId": "68cf1e5f-5069-43a0-d74d-dea0dc4a0c24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (91.189.88.24)] [Connected to cloud.r-pro\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r0% [1 InRelease gpgv 242 kB] [2 InRelease 14.2 kB/88.7 kB 16%] [Connecting to s\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 242 kB] [2 InRelease 72.1 kB/88.7 kB 81%] [Waiting for hea\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Waiting for headers] [Waiti\r                                                                               \rHit:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Waiting for headers] [Waiti\r                                                                               \rGet:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "\r0% [1 InRelease gpgv 242 kB] [5 InRelease 8,396 B/74.6 kB 11%] [Waiting for hea\r                                                                               \rHit:6 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 242 kB] [5 InRelease 73.6 kB/74.6 kB 99%] [Waiting for hea\r                                                                               \rGet:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [1 InRelease gpgv 242 kB] [5 InRelease 74.6 kB/74.6 kB 100%] [7 InRelease 2,\r0% [1 InRelease gpgv 242 kB] [7 InRelease 2,587 B/88.7 kB 3%] [Waiting for head\r                                                                               \rIgn:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 242 kB] [7 InRelease 8,379 B/88.7 kB 9%] [Connecting to pp\r                                                                               \rHit:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [1 InRelease gpgv 242 kB] [7 InRelease 11.3 kB/88.7 kB 13%] [Connecting to p\r                                                                               \rHit:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:11 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 2s (165 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ32MNeKH6_f",
        "colab_type": "text"
      },
      "source": [
        "Take a look at files and directories in the current directory (on Google Drive)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-VEGhGWEQfd",
        "colab_type": "code",
        "outputId": "f4cfc73d-e30d-4027-f71f-4be62eb2aa16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\t\t       spark-2.4.5-bin-hadoop2.7.tgz\n",
            "spark-2.3.2-bin-hadoop2.7      spark-2.4.5-bin-hadoop2.7.tgz.1\n",
            "spark-2.3.2-bin-hadoop2.7.tgz  spark-2.4.5-bin-hadoop2.7.tgz.2\n",
            "spark-2.4.5-bin-hadoop2.7      spark-2.4.5-bin-hadoop2.7.tgz.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gA1fcxuh1Tc",
        "colab_type": "text"
      },
      "source": [
        "Switch to OpenJDK Java 8 if it is Java 11 now. The reason is there are some bugs in Spark with Java 11. In the following enter the number that represents the installation of Java 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XSvjF_TiBfr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "d6a36c69-4150-468d-8d2c-483e4c74ccef"
      },
      "source": [
        "!update-alternatives --config java"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 2 choices for the alternative java (providing /usr/bin/java).\n",
            "\n",
            "  Selection    Path                                            Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      auto mode\n",
            "  1            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      manual mode\n",
            "  2            /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java   1081      manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 2\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOQBa3nJiIGT",
        "colab_type": "text"
      },
      "source": [
        "Make sure you have Jave 8 selected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL9hDUL0iKb0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "85c5d6d0-bd12-4231-af96-f5403ad23dc0"
      },
      "source": [
        "!java -version "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_242\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08)\n",
            "OpenJDK 64-Bit Server VM (build 25.242-b08, mixed mode)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oanbJ7fgH2FK",
        "colab_type": "text"
      },
      "source": [
        "Setting the Environment Variables (home directory) for Java and Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCZQ04sPwYZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XTiOJc-IEq4",
        "colab_type": "text"
      },
      "source": [
        "This will start a local Spark session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbFrwg-CvWrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init(\"/content/spark-2.4.5-bin-hadoop2.7\")\n",
        "from pyspark.sql import SparkSession\n",
        "# Sets the Spark master URL to connect to, such as \"local\" to run locally, \n",
        "# \"local[4]\" to run locally with 4 cores, or \"spark://master:7077\" to run on a Spark standalone cluster.\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate() #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziJ_nbkqLHEz",
        "colab_type": "text"
      },
      "source": [
        "Now use Spark. That's all there is to it - you're ready to use Spark!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0MYhlFTwd_P",
        "colab_type": "code",
        "outputId": "b64caa25-74fd-4a01-d69e-bb8af98834a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "# Some deprecation warning suppressed\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "df = spark.createDataFrame([{\"hello\": \"world\"} for x in range(1000)])\n",
        "df.show(3)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+\n",
            "|hello|\n",
            "+-----+\n",
            "|world|\n",
            "|world|\n",
            "|world|\n",
            "+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}