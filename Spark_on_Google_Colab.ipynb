{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark on Google Colab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waltz2u/bd/blob/master/Spark_on_Google_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5HTg9ntvFb6",
        "colab_type": "code",
        "outputId": "52cf93d5-034e-4c9e-c39c-1d6ee055cc27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-2.3.2/spark-2.3.2-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.3.2-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.2-bin-hadoop2.7\"\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (91.189.88.24)] [Connected to cloud.r-pro\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connected to cloud.r-projec\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Waiting for headers] [Waiti\r                                                                               \rHit:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Waiting for headers] [Waiti\r                                                                               \rHit:6 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\r                                                                               \r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Waiting for headers]\r                                                                        \rHit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "\r                                                                        \r0% [1 InRelease gpgv 242 kB] [Waiting for headers]\r                                                  \rIgn:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 242 kB] [Connecting to ppa.launchpad.net (91.189.95.83)]\r                                                                             \rHit:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [1 InRelease gpgv 242 kB] [Connecting to ppa.launchpad.net (91.189.95.83)]\r                                                                             \rHit:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:11 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oanbJ7fgH2FK",
        "colab_type": "text"
      },
      "source": [
        "Setting home directory for Java and Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCZQ04sPwYZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.2-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ32MNeKH6_f",
        "colab_type": "text"
      },
      "source": [
        "Take a look at files and directories in the current directory (on Google Drive)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-VEGhGWEQfd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "401e21d0-4856-4815-da7b-adc88589407f"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\t\t       spark-2.4.5-bin-hadoop2.7\n",
            "spark-2.3.2-bin-hadoop2.7      spark-2.4.5-bin-hadoop2.7.tgz\n",
            "spark-2.3.2-bin-hadoop2.7.tgz  spark-2.4.5-bin-hadoop2.7.tgz.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XTiOJc-IEq4",
        "colab_type": "text"
      },
      "source": [
        "Initialize FindSpark with spark-2.3.2-bin-hadoop2.7 directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbFrwg-CvWrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init(\"/content/spark-2.3.2-bin-hadoop2.7\")\n",
        "from pyspark.sql import SparkSession\n",
        "# Sets the Spark master URL to connect to, such as \"local\" to run locally, \n",
        "# \"local[4]\" to run locally with 4 cores, or \"spark://master:7077\" to run on a Spark standalone cluster.\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate() #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0MYhlFTwd_P",
        "colab_type": "code",
        "outputId": "52013ab3-6ab8-4cfa-b76e-d74777385cce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "df = spark.createDataFrame([{\"hello\": \"world\"} for x in range(1000)])\n",
        "df.show(3)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+\n",
            "|hello|\n",
            "+-----+\n",
            "|world|\n",
            "|world|\n",
            "|world|\n",
            "+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}