{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning3D",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waltz2u/bd/blob/master/DeepLearning3D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSoqqrgkOxmO",
        "colab_type": "text"
      },
      "source": [
        "Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AahhUjBFsT2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fdb683a6-a06e-4aef-953a-7deb768374f8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvFHVWAMO0vi",
        "colab_type": "text"
      },
      "source": [
        "Needs to crop so need to get the min size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLx24M_EFZWj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6301b95-adaf-49c7-8d39-92fb99a3034d"
      },
      "source": [
        "from PIL import Image\n",
        "import glob\n",
        "import pickle\n",
        "import functools as ft\n",
        "import numpy as np\n",
        "image_sizes = []\n",
        "for filename in glob.glob('/content/gdrive/My Drive/models/3d/*.jpg'): #assuming jpg\n",
        "    im = Image.open(filename)\n",
        "    image_sizes.append(im.size)    \n",
        "\n",
        "min_size = list(ft.reduce(lambda x,y: [min(x[0],y[0]), min(x[1],y[1])] , image_sizes))  \n",
        "print(min_size)  "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[701, 341]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vzImXlLO7Sa",
        "colab_type": "text"
      },
      "source": [
        "Crop all the images then store "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Kh19lPBK6FW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "area = (0,0,min_size[0],min_size[1])  \n",
        "images_list = np.empty(shape=[len(image_sizes),min_size[0], min_size[1], 3])\n",
        "i = 0\n",
        "for filename in glob.glob('/content/gdrive/My Drive/models/3d/*.jpg'): #assuming jpg\n",
        "    im = Image.open(filename)\n",
        "    im = im.crop(area)\n",
        "    #tt = np.array(im)\n",
        "    #print(tt.shape)\n",
        "    #break\n",
        "    image = np.transpose(np.array(im),[1,0,2])\n",
        "    #print(image.shape)\n",
        "    #break\n",
        "    images_list[i] = image\n",
        "    i += 1\n",
        "    #images_list.append(im.getdata())   \n",
        "    #in_data = np.asarray(images_list[0].getdata())\n",
        "    #in_data.T\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhXCmh9JTa4m",
        "colab_type": "text"
      },
      "source": [
        "Splitting training/test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9nJK7727xDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "num_classes = 3\n",
        "sample_size = len(images_list)\n",
        "sample_size_class = round(len(images_list)/num_classes)\n",
        "training_split = 0.7\n",
        "k = round(training_split * sample_size_class)\n",
        "m = sample_size_class - k\n",
        "training_index = random.sample(range(sample_size_class), k) + random.sample(range(sample_size_class, 2*sample_size_class), k) + random.sample(range(2*sample_size_class, 3*sample_size_class), k) \n",
        "test_index = [e for e in range(3*sample_size_class) if e not in training_index]\n",
        "# images_list_array = np.asarray(images_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ucCRAqxcs4r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c8d0bf4-db79-4523-ad19-32f38215a39a"
      },
      "source": [
        "len(training_index)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "189"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCnkkLfrTrCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train = images_list[training_index], [0]*k + [1]*k + [2]*k\n",
        "x_test, y_test = images_list[test_index], [0]*m + [1]*m + [2]*m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAvbGaahv3Ad",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14c24488-a45d-40a8-fe33-cfc9bfa6098b"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(189, 701, 341, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lshbw28IZKpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "049ozEhxWnq9",
        "colab_type": "text"
      },
      "source": [
        "The model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWMEz8ZF9sJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(min_size[0], min_size[1],3) ))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "pickle.dump(model, open('cnn/dl_estimator.sav', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOlg26_5Kg_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}