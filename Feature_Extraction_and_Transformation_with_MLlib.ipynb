{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "Feature Extraction and Transformation with MLlib.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waltz2u/bd/blob/master/Feature_Extraction_and_Transformation_with_MLlib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6QDDzDzGYzy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "21cd58ca-afb7-40e7-a534-ca55f487db2f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjQXqi0CGmL5",
        "colab_type": "text"
      },
      "source": [
        "# Setting things up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU9L-vnwGoSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "b0101afd-06d6-4d62-d914-825733a632ac"
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Waiting for headers] [Co\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:6 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:11 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:14 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,784 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [832 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,151 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [857 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,361 kB]\n",
            "Get:19 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [861 kB]\n",
            "Fetched 7,117 kB in 4s (1,836 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgT8IZ_DGt7p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aae45360-c192-4359-f00b-0af4187d2ebf"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tsample_data  spark-2.4.5-bin-hadoop2.7\tspark-2.4.5-bin-hadoop2.7.tgz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLvQboIZGwmR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "98971364-c312-4c8e-b240-1f40c12b1d04"
      },
      "source": [
        "!update-alternatives --config java"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 2 choices for the alternative java (providing /usr/bin/java).\n",
            "\n",
            "  Selection    Path                                            Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      auto mode\n",
            "  1            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      manual mode\n",
            "  2            /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java   1081      manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 2\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqsqr1oEG0Zb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a051c461-835e-4b79-d4ff-f755a0955bce"
      },
      "source": [
        "!java -version "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_242\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08)\n",
            "OpenJDK 64-Bit Server VM (build 25.242-b08, mixed mode)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4Ga3UBLG3CJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f11B2fTfGRIn",
        "colab_type": "text"
      },
      "source": [
        "# Feature Extraction and Transformation with MLlib\n",
        "Read for more about feature Extraction and Transformation with MLlib\n",
        "https://spark.apache.org/docs/latest/mllib-feature-extraction.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQhzc7AVGRIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init(\"/content/spark-2.4.5-bin-hadoop2.7\")\n",
        "from pyspark.sql import SparkSession\n",
        "# Sets the Spark master URL to connect to, such as \"local\" to run locally, \n",
        "# \"local[4]\" to run locally with 4 cores, or \"spark://master:7077\" to run on a Spark standalone cluster.\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate() #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AxD_XH0GRIz",
        "colab_type": "text"
      },
      "source": [
        "## TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nnsF3KTGRI0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "73344b09-7a5b-4515-bf3f-e8d18a5ff908"
      },
      "source": [
        "data = spark.createDataFrame([\n",
        "    (0.0, \"We start learning Spark\"),\n",
        "    (0.0, \"Python and R have API to work with it\"),\n",
        "    (1.0, \"We use Kmeans to cluster stock movement\"),\n",
        "    (1.0, \"We use logistic regression to predict bankruptcy\")\n",
        "], [\"label\", \"content\"])\n",
        "\n",
        "data.select('content').show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|             content|\n",
            "+--------------------+\n",
            "|We start learning...|\n",
            "|Python and R have...|\n",
            "|We use Kmeans to ...|\n",
            "|We use logistic r...|\n",
            "+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVgCHZIuGRI5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "2af3ddf7-42f4-47e7-aea4-d31216453a1d"
      },
      "source": [
        "data.select('content').rdd.collect()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(content='We start learning Spark'),\n",
              " Row(content='Python and R have API to work with it'),\n",
              " Row(content='We use Kmeans to cluster stock movement'),\n",
              " Row(content='We use logistic regression to predict bankruptcy')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmpPsTdFGRI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer,StopWordsRemover\n",
        "from pyspark.mllib.regression import LabeledPoint\n",
        "from pyspark.mllib.classification import NaiveBayes   \n",
        "from pyspark.sql import SQLContext, Row\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "from operator import itemgetter\n",
        "\n",
        "# tokenizer to create a \"terms\" column so for example:\n",
        "# from content=u'We start learning Spark'  we have terms=[u'we', u'start', u'learning', u'spark']\n",
        "tokenizer = Tokenizer(inputCol=\"content\", outputCol=\"terms\")\n",
        "termsData = tokenizer.transform(data)\n",
        "\n",
        "# remover to remove stop words that don't contribute so for example\n",
        "# from terms=[u'we', u'start', u'learning', u'spark'] we have filtered=[u'start', u'learning', u'spark']\n",
        "remover = StopWordsRemover(inputCol=\"terms\", outputCol=\"filtered\")\n",
        "filteredTermsData = remover.transform(termsData)\n",
        "\n",
        "# http://spark.apache.org/docs/latest/ml-features.html\n",
        "# Both HashingTF and CountVectorizer can be used to generate the term frequency vectors.\n",
        "# HashingTF is a Transformer which takes sets of terms and converts those sets into fixed-length feature vectors. In text processing, a “set of terms” might # be a bag of words. HashingTF utilizes the hashing trick. \n",
        "# so from filtered=[u'start', u'learning', u'spark'] we have rawFeatures=SparseVector(262144, {29470: 1.0, 62173: 1.0, 181346: 1.0})\n",
        "tf = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10).transform(filteredTermsData)\n",
        "\n",
        "# IDF: IDF is an Estimator which is fit on a dataset and produces an IDFModel. The IDFModel takes feature vectors (generally created from HashingTF or \n",
        "# CountVectorizer) and scales each column. Intuitively, it down-weights columns which appear frequently in a corpus.\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\").fit(tf)\n",
        "\n",
        "# TF-IDF\n",
        "tfidf = idf.transform(tf)\n",
        "\n",
        "labels = data.rdd.map(\n",
        "    lambda doc: doc[\"label\"]  # Standard Python dict access \n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU4c88nGGRJE",
        "colab_type": "text"
      },
      "source": [
        "Now take a look at tokenized data in termsData. \n",
        "\n",
        "tokenizer to create a \"terms\" column so for exampl, from content=u'We start learning Spark', we have terms=[u'we', u'start', u'learning', u'spark']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCAUg21xGRJG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "6fd192af-5c40-4d2b-a31f-06e40050a711"
      },
      "source": [
        "termsData.collect()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(label=0.0, content='We start learning Spark', terms=['we', 'start', 'learning', 'spark']),\n",
              " Row(label=0.0, content='Python and R have API to work with it', terms=['python', 'and', 'r', 'have', 'api', 'to', 'work', 'with', 'it']),\n",
              " Row(label=1.0, content='We use Kmeans to cluster stock movement', terms=['we', 'use', 'kmeans', 'to', 'cluster', 'stock', 'movement']),\n",
              " Row(label=1.0, content='We use logistic regression to predict bankruptcy', terms=['we', 'use', 'logistic', 'regression', 'to', 'predict', 'bankruptcy'])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvaXfd0gGRJL",
        "colab_type": "text"
      },
      "source": [
        "The remover is to remove stop words that don't contribute so for example, from terms=[u'we', u'start', u'learning', u'spark'] we have filtered=[u'start', u'learning', u'spark']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dSCa9exGRJN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "f68019b4-f84a-4698-e8a2-a92141395528"
      },
      "source": [
        "filteredTermsData.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(label=0.0, content='We start learning Spark', terms=['we', 'start', 'learning', 'spark'], filtered=['start', 'learning', 'spark']),\n",
              " Row(label=0.0, content='Python and R have API to work with it', terms=['python', 'and', 'r', 'have', 'api', 'to', 'work', 'with', 'it'], filtered=['python', 'r', 'api', 'work']),\n",
              " Row(label=1.0, content='We use Kmeans to cluster stock movement', terms=['we', 'use', 'kmeans', 'to', 'cluster', 'stock', 'movement'], filtered=['use', 'kmeans', 'cluster', 'stock', 'movement']),\n",
              " Row(label=1.0, content='We use logistic regression to predict bankruptcy', terms=['we', 'use', 'logistic', 'regression', 'to', 'predict', 'bankruptcy'], filtered=['use', 'logistic', 'regression', 'predict', 'bankruptcy'])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezerTunmGRJQ",
        "colab_type": "text"
      },
      "source": [
        "Both HashingTF and CountVectorizer can be used to generate the term frequency vectors.\n",
        "\n",
        "HashingTF is a Transformer which takes sets of terms and converts those sets into fixed-length feature vectors. In text processing, a “set of terms” might be a bag of words. HashingTF utilizes the hashing trick. So from filtered=[u'start', u'learning', u'spark'] we have rawFeatures=SparseVector(10, {2: 1.0, 5: 1.0, 6: 1.0}))\n",
        "\n",
        "Note that the numFeatures=10 in HashingTF decides the size of SparseVector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfYMzRyYGRJS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "28003543-4b78-4644-8035-e603878c298f"
      },
      "source": [
        "tf.collect()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(label=0.0, content='We start learning Spark', terms=['we', 'start', 'learning', 'spark'], filtered=['start', 'learning', 'spark'], rawFeatures=SparseVector(10, {2: 1.0, 5: 1.0, 6: 1.0})),\n",
              " Row(label=0.0, content='Python and R have API to work with it', terms=['python', 'and', 'r', 'have', 'api', 'to', 'work', 'with', 'it'], filtered=['python', 'r', 'api', 'work'], rawFeatures=SparseVector(10, {0: 1.0, 4: 1.0, 7: 1.0, 9: 1.0})),\n",
              " Row(label=1.0, content='We use Kmeans to cluster stock movement', terms=['we', 'use', 'kmeans', 'to', 'cluster', 'stock', 'movement'], filtered=['use', 'kmeans', 'cluster', 'stock', 'movement'], rawFeatures=SparseVector(10, {0: 1.0, 2: 1.0, 4: 1.0, 5: 1.0, 9: 1.0})),\n",
              " Row(label=1.0, content='We use logistic regression to predict bankruptcy', terms=['we', 'use', 'logistic', 'regression', 'to', 'predict', 'bankruptcy'], filtered=['use', 'logistic', 'regression', 'predict', 'bankruptcy'], rawFeatures=SparseVector(10, {3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 9: 1.0}))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-ICatOEGRJY",
        "colab_type": "text"
      },
      "source": [
        "HashingTF takes sets of terms and converts those sets into fixed-length feature vectors. In text processing, a “set of terms” might be a bag of words. HashingTF utilizes the hashing trick. A raw feature is mapped into an index (term) by applying a hash function. The hash function used here is MurmurHash 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE3_xCIkGRJZ",
        "colab_type": "text"
      },
      "source": [
        "Now look at tfidf, in features, this is where data is ready for modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S47QAU8vGRJZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "d0e0ab6b-9408-4c3d-eb69-a192bddc7aba"
      },
      "source": [
        "tfidf.collect()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(label=0.0, content='We start learning Spark', terms=['we', 'start', 'learning', 'spark'], filtered=['start', 'learning', 'spark'], rawFeatures=SparseVector(10, {2: 1.0, 5: 1.0, 6: 1.0}), features=SparseVector(10, {2: 0.5108, 5: 0.2231, 6: 0.5108})),\n",
              " Row(label=0.0, content='Python and R have API to work with it', terms=['python', 'and', 'r', 'have', 'api', 'to', 'work', 'with', 'it'], filtered=['python', 'r', 'api', 'work'], rawFeatures=SparseVector(10, {0: 1.0, 4: 1.0, 7: 1.0, 9: 1.0}), features=SparseVector(10, {0: 0.5108, 4: 0.2231, 7: 0.9163, 9: 0.2231})),\n",
              " Row(label=1.0, content='We use Kmeans to cluster stock movement', terms=['we', 'use', 'kmeans', 'to', 'cluster', 'stock', 'movement'], filtered=['use', 'kmeans', 'cluster', 'stock', 'movement'], rawFeatures=SparseVector(10, {0: 1.0, 2: 1.0, 4: 1.0, 5: 1.0, 9: 1.0}), features=SparseVector(10, {0: 0.5108, 2: 0.5108, 4: 0.2231, 5: 0.2231, 9: 0.2231})),\n",
              " Row(label=1.0, content='We use logistic regression to predict bankruptcy', terms=['we', 'use', 'logistic', 'regression', 'to', 'predict', 'bankruptcy'], filtered=['use', 'logistic', 'regression', 'predict', 'bankruptcy'], rawFeatures=SparseVector(10, {3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 9: 1.0}), features=SparseVector(10, {3: 0.9163, 4: 0.2231, 5: 0.2231, 6: 0.5108, 9: 0.2231}))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9R6zJH4GRJe",
        "colab_type": "text"
      },
      "source": [
        "Note that if above we do not specify inputCol and outputCol, the structures would be simple, like (for testing, try it on your own)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBr5MiVRGRJf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "47e271e8-ca2e-407c-8224-0a7f9cc0d990"
      },
      "source": [
        "tf.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(label=0.0, content='We start learning Spark', terms=['we', 'start', 'learning', 'spark'], filtered=['start', 'learning', 'spark'], rawFeatures=SparseVector(10, {2: 1.0, 5: 1.0, 6: 1.0})),\n",
              " Row(label=0.0, content='Python and R have API to work with it', terms=['python', 'and', 'r', 'have', 'api', 'to', 'work', 'with', 'it'], filtered=['python', 'r', 'api', 'work'], rawFeatures=SparseVector(10, {0: 1.0, 4: 1.0, 7: 1.0, 9: 1.0})),\n",
              " Row(label=1.0, content='We use Kmeans to cluster stock movement', terms=['we', 'use', 'kmeans', 'to', 'cluster', 'stock', 'movement'], filtered=['use', 'kmeans', 'cluster', 'stock', 'movement'], rawFeatures=SparseVector(10, {0: 1.0, 2: 1.0, 4: 1.0, 5: 1.0, 9: 1.0})),\n",
              " Row(label=1.0, content='We use logistic regression to predict bankruptcy', terms=['we', 'use', 'logistic', 'regression', 'to', 'predict', 'bankruptcy'], filtered=['use', 'logistic', 'regression', 'predict', 'bankruptcy'], rawFeatures=SparseVector(10, {3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 9: 1.0}))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE2CJ6Z8GRJj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "c82765bb-9589-40d0-eeb1-87b3392490f8"
      },
      "source": [
        "tfidf.collect()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(label=0.0, content='We start learning Spark', terms=['we', 'start', 'learning', 'spark'], filtered=['start', 'learning', 'spark'], rawFeatures=SparseVector(10, {2: 1.0, 5: 1.0, 6: 1.0}), features=SparseVector(10, {2: 0.5108, 5: 0.2231, 6: 0.5108})),\n",
              " Row(label=0.0, content='Python and R have API to work with it', terms=['python', 'and', 'r', 'have', 'api', 'to', 'work', 'with', 'it'], filtered=['python', 'r', 'api', 'work'], rawFeatures=SparseVector(10, {0: 1.0, 4: 1.0, 7: 1.0, 9: 1.0}), features=SparseVector(10, {0: 0.5108, 4: 0.2231, 7: 0.9163, 9: 0.2231})),\n",
              " Row(label=1.0, content='We use Kmeans to cluster stock movement', terms=['we', 'use', 'kmeans', 'to', 'cluster', 'stock', 'movement'], filtered=['use', 'kmeans', 'cluster', 'stock', 'movement'], rawFeatures=SparseVector(10, {0: 1.0, 2: 1.0, 4: 1.0, 5: 1.0, 9: 1.0}), features=SparseVector(10, {0: 0.5108, 2: 0.5108, 4: 0.2231, 5: 0.2231, 9: 0.2231})),\n",
              " Row(label=1.0, content='We use logistic regression to predict bankruptcy', terms=['we', 'use', 'logistic', 'regression', 'to', 'predict', 'bankruptcy'], filtered=['use', 'logistic', 'regression', 'predict', 'bankruptcy'], rawFeatures=SparseVector(10, {3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 9: 1.0}), features=SparseVector(10, {3: 0.9163, 4: 0.2231, 5: 0.2231, 6: 0.5108, 9: 0.2231}))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76W4R5zdGRJo",
        "colab_type": "text"
      },
      "source": [
        "A little bit more about SparseVector: \n",
        "\n",
        "In the following example for SparseVector, the second argument of Vectors.sparse is an array of the indices, and the third argument is the array of the actual values in those indices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr3pHxDjGRJp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3cf9f72a-7605-43c9-e841-15b6a48862d6"
      },
      "source": [
        "from pyspark.mllib.linalg import SparseVector\n",
        "vec = SparseVector(3, [0, 2], [1.0, 3.0])\n",
        "vec"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SparseVector(3, {0: 1.0, 2: 3.0})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1czYphTGRJs",
        "colab_type": "text"
      },
      "source": [
        "another way to create a SparseVector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRRWgFCTGRJs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "643e1cb4-acba-4c40-efc6-79b5fc95647a"
      },
      "source": [
        "from pyspark.mllib.linalg import Vectors\n",
        "vec = Vectors.sparse(3, [0, 2], [1.0, 3.0])\n",
        "vec"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SparseVector(3, {0: 1.0, 2: 3.0})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ9_G2K-GRJx",
        "colab_type": "text"
      },
      "source": [
        "If you would like to see what a SparseVector is in the form of a DenseVector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lkyGAjDGRJy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef266210-b329-4a80-9494-eca47bda39e3"
      },
      "source": [
        "from pyspark.mllib.linalg import SparseVector, DenseVector\n",
        "\n",
        "DenseVector(vec)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseVector([1.0, 0.0, 3.0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu2pVO1hGRJ2",
        "colab_type": "text"
      },
      "source": [
        "A sparse vector is represented by two parallel arrays: indices and values. Zero entries are not stored. A dense vector is backed by a double array representing its entries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBDugrPpGRJ5",
        "colab_type": "text"
      },
      "source": [
        "# StandardScaler\n",
        "\n",
        "Standardizes features by scaling to unit variance and/or removing the mean using column summary statistics on the samples in the training set. This is a very common pre-processing step. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVEl4u2OGRJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.mllib.feature import StandardScaler, StandardScalerModel\n",
        "from pyspark.mllib.linalg import Vectors\n",
        "from pyspark.mllib.util import MLUtils\n",
        "\n",
        "sc = SparkContext.getOrCreate()\n",
        "\n",
        "data = MLUtils.loadLibSVMFile(sc, r\"/content/spark-2.4.5-bin-hadoop2.7/data/mllib/sample_libsvm_data.txt\")\n",
        "label = data.map(lambda x: x.label)\n",
        "features = data.map(lambda x: x.features)\n",
        "\n",
        "scaler1 = StandardScaler().fit(features)\n",
        "scaler2 = StandardScaler(withMean=True, withStd=True).fit(features)\n",
        "\n",
        "# data1 will be unit variance.\n",
        "data1 = label.zip(scaler1.transform(features))\n",
        "\n",
        "# data2 will be unit variance and zero mean.\n",
        "data2 = label.zip(scaler2.transform(features.map(lambda x: Vectors.dense(x.toArray()))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzYDlb-KGRJ9",
        "colab_type": "text"
      },
      "source": [
        "Now take a look at the scaled data using take method of RDDs. Note that data1 is an RDD of SparseVector, while data2 is an RDD of DenVector using map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVEEBt8YGRKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "90886b94-5657-4e9f-fa07-9d688d49bb9a"
      },
      "source": [
        "features.take(1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SparseVector(692, {127: 51.0, 128: 159.0, 129: 253.0, 130: 159.0, 131: 50.0, 154: 48.0, 155: 238.0, 156: 252.0, 157: 252.0, 158: 252.0, 159: 237.0, 181: 54.0, 182: 227.0, 183: 253.0, 184: 252.0, 185: 239.0, 186: 233.0, 187: 252.0, 188: 57.0, 189: 6.0, 207: 10.0, 208: 60.0, 209: 224.0, 210: 252.0, 211: 253.0, 212: 252.0, 213: 202.0, 214: 84.0, 215: 252.0, 216: 253.0, 217: 122.0, 235: 163.0, 236: 252.0, 237: 252.0, 238: 252.0, 239: 253.0, 240: 252.0, 241: 252.0, 242: 96.0, 243: 189.0, 244: 253.0, 245: 167.0, 262: 51.0, 263: 238.0, 264: 253.0, 265: 253.0, 266: 190.0, 267: 114.0, 268: 253.0, 269: 228.0, 270: 47.0, 271: 79.0, 272: 255.0, 273: 168.0, 289: 48.0, 290: 238.0, 291: 252.0, 292: 252.0, 293: 179.0, 294: 12.0, 295: 75.0, 296: 121.0, 297: 21.0, 300: 253.0, 301: 243.0, 302: 50.0, 316: 38.0, 317: 165.0, 318: 253.0, 319: 233.0, 320: 208.0, 321: 84.0, 328: 253.0, 329: 252.0, 330: 165.0, 343: 7.0, 344: 178.0, 345: 252.0, 346: 240.0, 347: 71.0, 348: 19.0, 349: 28.0, 356: 253.0, 357: 252.0, 358: 195.0, 371: 57.0, 372: 252.0, 373: 252.0, 374: 63.0, 384: 253.0, 385: 252.0, 386: 195.0, 399: 198.0, 400: 253.0, 401: 190.0, 412: 255.0, 413: 253.0, 414: 196.0, 426: 76.0, 427: 246.0, 428: 252.0, 429: 112.0, 440: 253.0, 441: 252.0, 442: 148.0, 454: 85.0, 455: 252.0, 456: 230.0, 457: 25.0, 466: 7.0, 467: 135.0, 468: 253.0, 469: 186.0, 470: 12.0, 482: 85.0, 483: 252.0, 484: 223.0, 493: 7.0, 494: 131.0, 495: 252.0, 496: 225.0, 497: 71.0, 510: 85.0, 511: 252.0, 512: 145.0, 520: 48.0, 521: 165.0, 522: 252.0, 523: 173.0, 538: 86.0, 539: 253.0, 540: 225.0, 547: 114.0, 548: 238.0, 549: 253.0, 550: 162.0, 566: 85.0, 567: 252.0, 568: 249.0, 569: 146.0, 570: 48.0, 571: 29.0, 572: 85.0, 573: 178.0, 574: 225.0, 575: 253.0, 576: 223.0, 577: 167.0, 578: 56.0, 594: 85.0, 595: 252.0, 596: 252.0, 597: 252.0, 598: 229.0, 599: 215.0, 600: 252.0, 601: 252.0, 602: 252.0, 603: 196.0, 604: 130.0, 622: 28.0, 623: 199.0, 624: 252.0, 625: 252.0, 626: 253.0, 627: 252.0, 628: 252.0, 629: 233.0, 630: 145.0, 651: 25.0, 652: 128.0, 653: 252.0, 654: 253.0, 655: 252.0, 656: 141.0, 657: 37.0})]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv-DsBcjGRKD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "57c75498-876e-4c31-9fca-78f222c5240f"
      },
      "source": [
        "data1.take(1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.0,\n",
              "  SparseVector(692, {127: 0.5468, 128: 1.5923, 129: 2.4354, 130: 1.7081, 131: 0.7335, 154: 0.4346, 155: 2.0985, 156: 2.2563, 157: 2.2368, 158: 2.2269, 159: 2.2555, 181: 0.4713, 182: 2.0575, 183: 2.3318, 184: 2.3761, 185: 2.1237, 186: 2.0452, 187: 2.2657, 188: 0.6339, 189: 0.1022, 207: 0.1056, 208: 0.5395, 209: 1.9268, 210: 2.2383, 211: 2.3018, 212: 2.3568, 213: 1.8002, 214: 0.7116, 215: 2.2256, 216: 2.4032, 217: 1.5931, 235: 1.5394, 236: 2.188, 237: 2.1493, 238: 2.2924, 239: 2.3889, 240: 2.3155, 241: 2.2653, 242: 0.8445, 243: 1.7094, 244: 2.2496, 245: 1.8613, 262: 0.5062, 263: 2.0796, 264: 2.2201, 265: 2.199, 266: 1.7299, 267: 1.083, 268: 2.1786, 269: 2.0345, 270: 0.4392, 271: 0.7218, 272: 2.2177, 273: 1.6764, 289: 0.4794, 290: 2.214, 291: 2.3569, 292: 2.2283, 293: 1.6322, 294: 0.1087, 295: 0.6833, 296: 1.0411, 297: 0.1941, 300: 2.277, 301: 2.3083, 302: 0.5395, 316: 0.3967, 317: 1.6059, 318: 2.3539, 319: 2.1535, 320: 1.9834, 321: 0.8017, 328: 2.4941, 329: 2.3661, 330: 1.7473, 343: 0.0763, 344: 1.7606, 345: 2.3044, 346: 2.2526, 347: 0.7221, 348: 0.2063, 349: 0.2749, 356: 2.5746, 357: 2.4037, 358: 1.9606, 371: 0.591, 372: 2.4489, 373: 2.3315, 374: 0.6414, 384: 2.5939, 385: 2.4196, 386: 1.8986, 399: 2.0016, 400: 2.3333, 401: 1.898, 412: 2.6198, 413: 2.4525, 414: 1.9856, 426: 0.783, 427: 2.3838, 428: 2.2811, 429: 1.1435, 440: 2.5745, 441: 2.4723, 442: 1.5716, 454: 0.8453, 455: 2.3533, 456: 2.1201, 457: 0.2628, 466: 0.0965, 467: 1.4473, 468: 2.5738, 469: 1.8242, 470: 0.1367, 482: 0.828, 483: 2.3418, 484: 2.0701, 493: 0.1335, 494: 1.4911, 495: 2.4922, 496: 2.224, 497: 0.7444, 510: 0.8429, 511: 2.314, 512: 1.3481, 520: 0.6477, 521: 1.9663, 522: 2.3879, 523: 1.6775, 538: 0.8901, 539: 2.3049, 540: 2.0206, 547: 1.1411, 548: 2.5098, 549: 2.3552, 550: 1.5115, 566: 1.0072, 567: 2.4162, 568: 2.2029, 569: 1.2616, 570: 0.4172, 571: 0.248, 572: 0.8054, 573: 1.6634, 574: 2.0511, 575: 2.349, 576: 2.0094, 577: 1.4659, 578: 0.5412, 594: 1.4063, 595: 2.5988, 596: 2.2365, 597: 2.175, 598: 1.9974, 599: 1.9218, 600: 2.3287, 601: 2.2914, 602: 2.2011, 603: 1.6439, 604: 1.1151, 622: 0.6799, 623: 2.7625, 624: 2.4617, 625: 2.2485, 626: 2.208, 627: 2.323, 628: 2.306, 629: 2.1166, 630: 1.2687, 651: 0.5922, 652: 1.7772, 653: 2.3485, 654: 2.1973, 655: 2.25, 656: 1.2522, 657: 0.3419}))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84e9vE7CGRKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0d3f6f10-3dcd-423a-c0f3-9a0649b7f9f1"
      },
      "source": [
        "data2.take(1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.0,\n",
              "  DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, -0.1, -0.1357, -0.1287, -0.1584, -0.1689, -0.1934, -0.1068, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, -0.1, -0.1338, -0.136, -0.2777, -0.4448, -0.5367, -0.6242, -0.1413, 0.8975, 1.6834, 1.0786, 0.2778, -0.2784, -0.1424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, -0.1, -0.1238, -0.1741, -0.2875, -0.436, -0.6436, -0.804, -0.5563, 0.9701, 1.0756, 1.0633, 1.2936, 1.5017, -0.4409, -0.2643, -0.1677, -0.1, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, -0.1508, -0.1988, -0.3025, -0.4146, -0.5285, -0.7426, -0.4867, 0.8363, 0.9642, 0.8776, 0.7981, 0.8759, 1.3475, 0.0532, -0.2638, -0.2351, -0.1, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1473, -0.2123, -0.293, -0.4025, -0.4646, -0.5713, -0.3357, 0.8337, 0.95, 0.9619, 0.8119, 0.3863, -0.4976, 1.1607, 1.6697, 1.1153, -0.2902, -0.1147, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, -0.1737, -0.2422, -0.3911, -0.4552, -0.6045, 0.7703, 1.2783, 1.0811, 1.0242, 1.0347, 0.9802, 0.9655, -0.316, 0.6902, 1.5056, 1.2792, -0.3696, -0.1914, -0.1051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.138, -0.2088, -0.3229, -0.4268, -0.5353, -0.2181, 1.2681, 1.352, 1.2355, 0.511, -0.174, 1.091, 1.0527, -0.497, -0.1119, 1.4806, 1.0511, -0.4797, -0.2665, -0.139, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1815, -0.2766, -0.3899, -0.4813, -0.1714, 1.4931, 1.6222, 1.465, 0.6979, -1.1195, -0.5165, 0.1072, -0.5779, -0.7185, -0.6714, 1.5629, 1.6563, 0.0125, -0.372, -0.1704, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2219, -0.3518, -0.4713, -0.1571, 0.923, 1.6792, 1.5087, 1.3118, -0.1217, -1.1901, -1.1254, -0.818, -0.6479, -0.5726, -0.5227, 1.8384, 1.7465, 1.1504, -0.4304, -0.2483, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2843, -0.4402, -0.4486, 1.1265, 1.6053, 1.6179, 0.1574, -0.3971, -0.6615, -1.1778, -1.0609, -0.7651, -0.5743, -0.4355, -0.439, 1.9493, 1.7853, 1.3685, -0.4806, -0.2961, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.3259, -0.481, 0.027, 1.7985, 1.6685, 0.0692, -0.4706, -0.6015, -1.0855, -1.1359, -1.0485, -0.693, -0.4395, -0.3876, -0.4275, 1.9906, 1.7809, 1.2915, -0.4895, -0.3128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, -0.3648, -0.52, 1.3905, 1.6753, 1.2655, -0.4698, -0.4063, -0.6375, -1.0602, -1.1191, -1.034, -0.558, -0.3725, -0.3325, -0.455, 2.033, 1.825, 1.4226, -0.4758, -0.3462, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1157, -0.4181, 0.2275, 1.734, 1.595, 0.5263, -0.434, -0.4101, -0.7107, -1.0713, -1.1114, -0.9221, -0.4328, -0.2785, -0.3406, -0.4726, 1.9588, 1.8771, 1.0205, -0.4533, -0.3306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1415, -0.448, 0.2602, 1.6644, 1.4284, -0.3049, -0.4354, -0.507, -0.7449, -1.0441, -1.0922, -0.7898, -0.3971, -0.239, -0.3188, 0.9086, 1.9452, 1.2092, -0.3608, -0.4134, -0.2729, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1694, -0.456, 0.2275, 1.6294, 1.3892, -0.5733, -0.5166, -0.5899, -0.7526, -1.0396, -1.026, -0.6517, -0.4169, -0.2134, 0.9901, 1.8713, 1.5363, 0.1588, -0.4628, -0.376, -0.2433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2164, -0.4189, 0.2681, 1.5761, 0.6285, -0.6115, -0.6262, -0.6558, -0.813, -1.0641, -0.8976, -0.6301, 0.177, 1.4175, 1.7782, 0.9774, -0.6336, -0.494, -0.412, -0.3218, -0.2188, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1784, -0.3798, 0.3457, 1.5867, 1.2237, -0.7649, -0.8005, -0.804, -0.9076, -1.0231, -0.9076, 0.4239, 1.8329, 1.684, 0.7991, -0.7001, -0.5941, -0.4748, -0.3513, -0.2637, -0.1811, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1344, -0.3229, 0.5249, 1.7598, 1.3422, 0.3071, -0.6148, -0.8446, -0.4383, 0.4311, 0.9389, 1.414, 1.1825, 0.6781, -0.2101, -0.6059, -0.5058, -0.4191, -0.3035, -0.207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, -0.1862, 0.9773, 1.9703, 1.404, 1.0334, 0.7065, 0.5383, 0.9214, 0.951, 0.9818, 0.5838, 0.1799, -0.7994, -0.668, -0.5031, -0.4184, -0.3189, -0.2282, -0.1715, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, -0.1277, 0.4065, 2.2617, 1.7001, 1.1174, 0.8526, 0.7972, 0.9024, 0.6975, -0.0193, -1.0764, -0.8589, -0.6716, -0.5148, -0.4466, -0.3258, -0.2422, -0.1195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, -0.156, 0.2961, 1.2624, 1.5267, 1.1794, 1.1322, 0.24, -0.6698, -0.9531, -0.7473, -0.5558, -0.4777, -0.3928, -0.3003, -0.1981, -0.1433, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.142, -0.1421, -0.1612, -0.3261, -0.3703, -0.3936, -0.3809, -0.3466, -0.4038, -0.3488, -0.2193, -0.1792, -0.1559, -0.1345]))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bHzwArPGRKK",
        "colab_type": "text"
      },
      "source": [
        "# MinMaxScaler\n",
        "\n",
        "MinMaxScaler transforms a dataset of Vector rows, rescaling each feature to a specific range (often [0, 1]). It takes parameters:\n",
        "\n",
        "min: 0.0 by default. Lower bound after transformation, shared by all features.\n",
        "    \n",
        "max: 1.0 by default. Upper bound after transformation, shared by all features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsw5Qr3PGRKM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "9d921310-50e4-414b-9baf-3d8aa5afac74"
      },
      "source": [
        "from pyspark.ml.feature import MinMaxScaler\n",
        "from pyspark.ml.linalg import Vectors\n",
        "\n",
        "dataFrame = spark.createDataFrame([\n",
        "    (0, Vectors.dense([1.0, 0.1, -1.0]),),\n",
        "    (1, Vectors.dense([2.0, 1.1, 1.0]),),\n",
        "    (2, Vectors.dense([3.0, 10.1, 3.0]),)\n",
        "], [\"id\", \"features\"])\n",
        "\n",
        "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
        "\n",
        "# Compute summary statistics and generate MinMaxScalerModel\n",
        "scalerModel = scaler.fit(dataFrame)\n",
        "\n",
        "# rescale each feature to range [min, max].\n",
        "scaledData = scalerModel.transform(dataFrame)\n",
        "print(\"Features scaled to range: [%f, %f]\" % (scaler.getMin(), scaler.getMax()))\n",
        "scaledData.select(\"features\", \"scaledFeatures\").show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features scaled to range: [0.000000, 1.000000]\n",
            "+--------------+--------------+\n",
            "|      features|scaledFeatures|\n",
            "+--------------+--------------+\n",
            "|[1.0,0.1,-1.0]| [0.0,0.0,0.0]|\n",
            "| [2.0,1.1,1.0]| [0.5,0.1,0.5]|\n",
            "|[3.0,10.1,3.0]| [1.0,1.0,1.0]|\n",
            "+--------------+--------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}